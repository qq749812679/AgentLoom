# ğŸŒŸ Multiâ€‘Modal AI Orchestrator

[ç®€ä½“ä¸­æ–‡](README.zh-CN.md) | English

<div align="center">

![Banner](https://img.shields.io/badge/Multi--Modal-AI%20Orchestrator-blue?style=for-the-badge&logo=robot&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.9+-blue?style=for-the-badge&logo=python&logoColor=white)
![React](https://img.shields.io/badge/React-18.2+-61DAFB?style=for-the-badge&logo=react&logoColor=black)
![LangGraph](https://img.shields.io/badge/LangGraph-ğŸ¦œ-green?style=for-the-badge)
![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white)

**The Agentic OS for synchronized TEXT ã€‚Image Â· Music Â· Lights Â· Video**

From one prompt to an immersive, productionâ€‘ready experience â€” with real devices.


<a href="https://qq749812679.github.io/Multi-Modal-AI-Orchestrator" target="_blank"><img src="https://img.shields.io/badge/Docs-Read%20the%20Docs-blue?style=for-the-badge" /></a>
<a href="#" target="_blank"><img src="https://img.shields.io/badge/Demo-Open%20Live%20Demo-orange?style=for-the-badge" /></a>

</div>

---

## ğŸš€ Why this project stands out

- ğŸ§  **Agentic orchestration, not scripts**: LangGraphâ€‘based multiâ€‘agent planning with memory, feedback, safety and collaboration.
- ğŸ›ï¸ **Textâ€‘toâ€‘Everything pipeline**: One workflow to generate image, compose music, choreograph lights, and render video.
- ğŸ’¡ **Deviceâ€‘native**: Firstâ€‘class Philips Hue / WLED control. Not just a demo â€” it runs your room.
- ğŸ”Œ **Pluggable backends**: SD WebUI / HTTP models hotâ€‘swappable with latency/cost profiling and health probing.
- ğŸ§ª **Feedback â†’ Autoâ€‘tuning**: Collect ratings, learn patterns, and surface optimization suggestions automatically.
- ğŸ“¦ **Task queue UX**: Pause / resume / retry with persistent progress cards.
- ğŸ§­ **Firstâ€‘run wizard**: Writes .env + device params in minutes.
- ğŸ¢ **Enterpriseâ€‘ready knobs**: License gating, audit logs, roleâ€‘based hooks.

## âœ¨ What you can build in 60 seconds

- â€œCozy jazz barâ€ â†’ cinematic image + mellow soundtrack + warm lighting show + MP4
- Upload a photo â†’ matching soundtrack + moodâ€‘aligned lighting
- Drop a song â†’ beatâ€‘synced lighting with presets for Hue/WLED

## âš¡ Quick start

### Windows (PowerShell)
1. `cd multiscen`
2. `powershell -ExecutionPolicy Bypass -File setup.ps1`
3. `streamlit run app.py`

### macOS/Linux
1. `cd multiscen && bash setup.sh`
2. `streamlit run app.py`

### Optional frontend (React)
- `cd multiscen/frontend && npm install && npm start`

### CLI
- `mscen gen "sunset jazz bar" --video`
- `mscen list`

## ğŸ¥Š How it beats typical alternatives

- **Unified multiâ€‘modal pipeline** vs singleâ€‘modality generators (imageâ€‘only or musicâ€‘only)
- **Deviceâ€‘native control** vs pure screen previews
- **Agentic planning + feedback learning** vs manual trialâ€‘andâ€‘error
- **Latency/cost profiling + task queue** vs blind requests with no operational UX
- **Onboarding wizard** vs handâ€‘editing envs and YAMLs

## ğŸ§© Architecture at a glance

- Backend: Streamlit + FastAPI + LangGraph, feedback learner, model optimizer
- Frontend: React + TypeScript + Tailwind, realâ€‘time agent/queue views
- Connectors: SD WebUI, HTTP image/music/STT/TTS, Hue/WLED devices
- Enterprise: License server, audit logger, security hooks

## ğŸ§ª Live demos

- Web UI: Textâ€‘toâ€‘Everything studio, realâ€‘time device control
- Mock API: `docker-compose up -d mock-api`
- Short video/GIFs: coming soon (PRs welcome!)

## ğŸ›£ï¸ Roadmap highlights

- Strategyâ€‘based routing (lowest latency / lowest cost / balanced)
- Autoâ€‘tuned parameter replay ("apply suggestions" oneâ€‘click)
- Multiâ€‘user spaces and approval workflows

## ğŸ¤ Contribute & grow with us

- Star â­ if this saves your time, PRs welcome!
- Use Issues for bugs/ideas, Discussions for design talks
- Sponsors/Backers: see `.github/FUNDING.yml`

## ğŸ“„ License

MIT â€” build amazing things.
